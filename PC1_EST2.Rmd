---
title: "PC1_EST2"
output: html_document
date: '2022-04-24'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```
```{r}
library(httr)
set_config(config(ssl_verifypeer = FALSE))
options(RCurlOptions = list(ssl_verifypeer = FALSE))
options(rsconnect.check.certificate = FALSE)
```
EJERCICIO 1
```{r}
miGIB="https://github.com/javi902/PC1_EST2"
```

EJERCICIO2
```{r}
miLLAVE="hTUOO41nlkh3fsTmsX11xw77Oz2PA5B22KclBrc7"
```

```{r}
link="http://api.datos.agrorural.gob.pe"
RQJSON="/api/v2/datastreams/"
GUID="PLANE-DE-NEGOC-DE-PROYE"
FORMATO="/data.json/" 
KEY="?auth_key="
```
```{r}
request=paste0(link,RQJSON,GUID,FORMATO,KEY,miLLAVE) # La función paste0 la usamos para concatenar todos los elementos sin separador
request #mirala
```
```{r}
library(jsonlite) 
AGRO = fromJSON(request) 
str(AGRO)
```
```{r}
dataAGRO=data.frame(AGRO$result)
head(dataAGRO)
library(rio)
export(dataAGRO, "data_1.csv") 
```

EJERCICIO 3
#1 FORMA CON LIBREAIA RGDAL
Mapa1
```{r}
library(sp)
library(rgdal)
fromGit=("https://github.com/javi902/PC1_EST2/blob/main/Red_Vial_Inca_Qhapaq_Nan_geogpsperu_SuyoPomaliaJuanPablo_931381206.json?raw=true")
wazipMap <- rgdal::readOGR(fromGit,stringsAsFactors = FALSE)
plot(wazipMap)

```

```{r}
#MAPA2
fromGit2=("https://github.com/javi902/PC1_EST2/blob/main/UH.json?raw=true")
wazipMap <- rgdal::readOGR(fromGit2,stringsAsFactors = FALSE)
plot(wazipMap)
```

#2FORMA CON LIBRERIA GGPLOT
```{r}
#Mapa3
library(ggplot2)
library(sf)
mapGLA=sf::read_sf("InventarioGlaciares.json")
mapGLA <- st_read("InventarioGlaciares.json") 
ggplot(mapGLA) + geom_sf()
```

```{r}
#MAPA 4
mapHUM=sf::read_sf("humedales_ramsar_z_18_wgs84.json")
mapHUM <- st_read("humedales_ramsar_z_18_wgs84.json")
ggplot(mapHUM) + geom_sf()
```

EJERCICIO 4
```{r}
#TABLA1
library(htmltab)
link1 = "https://es.wikipedia.org/wiki/%C3%8Dndice_de_Libertad_Econ%C3%B3mica"
path1 = "/html/body/div[3]/div[3]/div[5]/div[1]/table[1]"
dataWS1 = htmltab(link1, path1)
head(dataWS1)
library(rio)
export(dataWS1, "data_2.csv") 
```

```{r}
#TABLA2
link2 = "https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_igualdad_de_ingreso"
path2 = "/html/body/div[3]/div[3]/div[5]/div[1]/table"
dataWS2 = htmltab(link2, path2)
head(dataWS2)
export(dataWS2, "data_3.csv") 
```

```{r}
#TABLA3
link3= "https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_IDH_ajustado_por_desigualdad"
path3 = "/html/body/div[3]/div[3]/div[5]/div[1]/div[3]/table"
dataWS3 = htmltab(link3, path3)
head(dataWS3)
export(dataWS3, "data_4.csv") 
```
```{r}
#TABLA4
link4= "https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_tasa_de_homicidio_intencional"
path4 = "/html/body/div[3]/div[3]/div[5]/div[1]/table[3]"
dataWS4 = htmltab(link4, path4)
head(dataWS4)
export(dataWS4, "data_5.csv") 
```
```{r}
#TABLA5
library(rvest)
url="https://datosmacro.expansion.com/estado/indice-percepcion-corrupcion"
pagina_web=read_html(url)
pagina_web
```
```{r}
css_pais="tr" 
pais_html <- html_nodes(pagina_web,css_pais) 
pais_texto <- html_text(pais_html) 
head(pais_texto)
```

```{r}
dataWS5 <- data.frame(PAIS = pais_texto)
head(dataWS5)
export(dataWS5, "data_6.csv")
```


EJERCICIO 5
```{r}
library(rvest) #para el scraping
library(dplyr) 
```

```{r}
url="http://www.infoartes.pe/f/formacion-1/talleres-especializacion/page/"
css_taller="div.item"

final_table = list() # list es una función para crear listas
```

Construimos la función e iteración

```{r}
for(i in 1:16) { # INPUT
  webpage <- read_html(paste0(url, i)) #obtenemos el código html de las 3 páginas
  taller_texto <- webpage %>%
    html_nodes(css_taller) %>% # obtener el código html del css del cargo
    html_text() # lo convertimos en un vector de texto
 

final_table[[i]] <- data.frame( TALLER=taller_texto) # OUTPUT: Con esto estamos creando una lista con 3 data frames que contenga las 3 páginas scrapeadas
}
```

```{r}
dataWS7 = bind_rows(final_table) # función de la librería dplyr que nos permite combinar filas de los tres data frame contenidos en la lista "final_table"
head(dataWS7)
export(dataWS7, "data_7.csv")
```
